# Generated by the Protocol Buffers compiler. DO NOT EDIT!
# source: openmodel/v2/inference.proto
# plugin: grpclib.plugin.main
import abc
import typing

import grpclib.const
import grpclib.client
if typing.TYPE_CHECKING:
    import grpclib.server

import google.protobuf.duration_pb2
import openmodel.v2.container_pb2
import openmodel.v2.results_pb2
import openmodel.v2.explanations_pb2
import openmodel.v2.drift_pb2
import openmodel.v2.inference_pb2


class InferenceServiceBase(abc.ABC):

    @abc.abstractmethod
    async def Status(self, stream: 'grpclib.server.Stream[openmodel.v2.inference_pb2.StatusRequest, openmodel.v2.inference_pb2.StatusResponse]') -> None:
        pass

    @abc.abstractmethod
    async def GetContainerInfo(self, stream: 'grpclib.server.Stream[openmodel.v2.inference_pb2.ContainerInfoRequest, openmodel.v2.container_pb2.OpenModelContainerInfo]') -> None:
        pass

    @abc.abstractmethod
    async def Predict(self, stream: 'grpclib.server.Stream[openmodel.v2.inference_pb2.PredictRequest, openmodel.v2.inference_pb2.PredictResponse]') -> None:
        pass

    @abc.abstractmethod
    async def Shutdown(self, stream: 'grpclib.server.Stream[openmodel.v2.inference_pb2.ShutdownRequest, openmodel.v2.inference_pb2.ShutdownResponse]') -> None:
        pass

    def __mapping__(self) -> typing.Dict[str, grpclib.const.Handler]:
        return {
            '/openmodel.v2.InferenceService/Status': grpclib.const.Handler(
                self.Status,
                grpclib.const.Cardinality.UNARY_UNARY,
                openmodel.v2.inference_pb2.StatusRequest,
                openmodel.v2.inference_pb2.StatusResponse,
            ),
            '/openmodel.v2.InferenceService/GetContainerInfo': grpclib.const.Handler(
                self.GetContainerInfo,
                grpclib.const.Cardinality.UNARY_UNARY,
                openmodel.v2.inference_pb2.ContainerInfoRequest,
                openmodel.v2.container_pb2.OpenModelContainerInfo,
            ),
            '/openmodel.v2.InferenceService/Predict': grpclib.const.Handler(
                self.Predict,
                grpclib.const.Cardinality.UNARY_UNARY,
                openmodel.v2.inference_pb2.PredictRequest,
                openmodel.v2.inference_pb2.PredictResponse,
            ),
            '/openmodel.v2.InferenceService/Shutdown': grpclib.const.Handler(
                self.Shutdown,
                grpclib.const.Cardinality.UNARY_UNARY,
                openmodel.v2.inference_pb2.ShutdownRequest,
                openmodel.v2.inference_pb2.ShutdownResponse,
            ),
        }


class InferenceServiceStub:

    def __init__(self, channel: grpclib.client.Channel) -> None:
        self.Status = grpclib.client.UnaryUnaryMethod(
            channel,
            '/openmodel.v2.InferenceService/Status',
            openmodel.v2.inference_pb2.StatusRequest,
            openmodel.v2.inference_pb2.StatusResponse,
        )
        self.GetContainerInfo = grpclib.client.UnaryUnaryMethod(
            channel,
            '/openmodel.v2.InferenceService/GetContainerInfo',
            openmodel.v2.inference_pb2.ContainerInfoRequest,
            openmodel.v2.container_pb2.OpenModelContainerInfo,
        )
        self.Predict = grpclib.client.UnaryUnaryMethod(
            channel,
            '/openmodel.v2.InferenceService/Predict',
            openmodel.v2.inference_pb2.PredictRequest,
            openmodel.v2.inference_pb2.PredictResponse,
        )
        self.Shutdown = grpclib.client.UnaryUnaryMethod(
            channel,
            '/openmodel.v2.InferenceService/Shutdown',
            openmodel.v2.inference_pb2.ShutdownRequest,
            openmodel.v2.inference_pb2.ShutdownResponse,
        )
