# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: openmodel/v2/inference.proto
# Protobuf Python Version: 4.25.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2
from openmodel.v2 import container_pb2 as openmodel_dot_v2_dot_container__pb2
from openmodel.v2 import results_pb2 as openmodel_dot_v2_dot_results__pb2
from openmodel.v2 import explanations_pb2 as openmodel_dot_v2_dot_explanations__pb2
from openmodel.v2 import drift_pb2 as openmodel_dot_v2_dot_drift__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1copenmodel/v2/inference.proto\x12\x0copenmodel.v2\x1a\x1egoogle/protobuf/duration.proto\x1a\x1copenmodel/v2/container.proto\x1a\x1aopenmodel/v2/results.proto\x1a\x1fopenmodel/v2/explanations.proto\x1a\x18openmodel/v2/drift.proto\"\x0f\n\rStatusRequest\"k\n\x0eStatusResponse\x12\x33\n\x06status\x18\x01 \x01(\x0e\x32#.openmodel.v2.StatusResponse.Status\"$\n\x06Status\x12\x12\n\x0eUNKNOWN_STATUS\x10\x00\x12\x06\n\x02OK\x10\x01\"\x16\n\x14\x43ontainerInfoRequest\"\xed\x01\n\x0ePredictRequest\x12\x32\n\x06inputs\x18\x01 \x03(\x0b\x32\".openmodel.v2.PredictRequest.Input\x12\x34\n\x04tags\x18\n \x03(\x0b\x32&.openmodel.v2.PredictRequest.TagsEntry\x1a>\n\x05Input\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x0e\n\x04text\x18\x02 \x01(\tH\x00\x12\x0e\n\x04\x64\x61ta\x18\x03 \x01(\x0cH\x00\x42\x08\n\x06source\x1a+\n\tTagsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01J\x04\x08\x02\x10\x03\"\xd5\x04\n\x0fPredictResponse\x12/\n\x07outputs\x18\x01 \x03(\x0b\x32\x1e.openmodel.v2.PredictionOutput\x12.\n\x0b\x65xplanation\x18\x02 \x01(\x0b\x32\x19.openmodel.v2.Explanation\x12\'\n\x05\x64rift\x18\x03 \x01(\x0b\x32\x18.openmodel.v2.ModelDrift\x12\x0f\n\x07success\x18\x07 \x01(\x08\x12\r\n\x05\x65rror\x18\x08 \x01(\t\x12\x36\n\x07timings\x18\t \x01(\x0b\x32%.openmodel.v2.PredictResponse.Timings\x12\x35\n\x04tags\x18\n \x03(\x0b\x32\'.openmodel.v2.PredictResponse.TagsEntry\x1a\xfb\x01\n\x07Timings\x12\x32\n\x0fmodel_execution\x18\x01 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x30\n\rpreprocessing\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x31\n\x0epostprocessing\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\x12-\n\nformatting\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12(\n\x05total\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x1a+\n\tTagsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x11\n\x0fShutdownRequest\"\x12\n\x10ShutdownResponse2\xd0\x02\n\x10InferenceService\x12\x45\n\x06Status\x12\x1b.openmodel.v2.StatusRequest\x1a\x1c.openmodel.v2.StatusResponse\"\x00\x12^\n\x10GetContainerInfo\x12\".openmodel.v2.ContainerInfoRequest\x1a$.openmodel.v2.OpenModelContainerInfo\"\x00\x12H\n\x07Predict\x12\x1c.openmodel.v2.PredictRequest\x1a\x1d.openmodel.v2.PredictResponse\"\x00\x12K\n\x08Shutdown\x12\x1d.openmodel.v2.ShutdownRequest\x1a\x1e.openmodel.v2.ShutdownResponse\"\x00\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'openmodel.v2.inference_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_PREDICTREQUEST_TAGSENTRY']._options = None
  _globals['_PREDICTREQUEST_TAGSENTRY']._serialized_options = b'8\001'
  _globals['_PREDICTRESPONSE_TAGSENTRY']._options = None
  _globals['_PREDICTRESPONSE_TAGSENTRY']._serialized_options = b'8\001'
  _globals['_STATUSREQUEST']._serialized_start=195
  _globals['_STATUSREQUEST']._serialized_end=210
  _globals['_STATUSRESPONSE']._serialized_start=212
  _globals['_STATUSRESPONSE']._serialized_end=319
  _globals['_STATUSRESPONSE_STATUS']._serialized_start=283
  _globals['_STATUSRESPONSE_STATUS']._serialized_end=319
  _globals['_CONTAINERINFOREQUEST']._serialized_start=321
  _globals['_CONTAINERINFOREQUEST']._serialized_end=343
  _globals['_PREDICTREQUEST']._serialized_start=346
  _globals['_PREDICTREQUEST']._serialized_end=583
  _globals['_PREDICTREQUEST_INPUT']._serialized_start=470
  _globals['_PREDICTREQUEST_INPUT']._serialized_end=532
  _globals['_PREDICTREQUEST_TAGSENTRY']._serialized_start=534
  _globals['_PREDICTREQUEST_TAGSENTRY']._serialized_end=577
  _globals['_PREDICTRESPONSE']._serialized_start=586
  _globals['_PREDICTRESPONSE']._serialized_end=1183
  _globals['_PREDICTRESPONSE_TIMINGS']._serialized_start=887
  _globals['_PREDICTRESPONSE_TIMINGS']._serialized_end=1138
  _globals['_PREDICTRESPONSE_TAGSENTRY']._serialized_start=534
  _globals['_PREDICTRESPONSE_TAGSENTRY']._serialized_end=577
  _globals['_SHUTDOWNREQUEST']._serialized_start=1185
  _globals['_SHUTDOWNREQUEST']._serialized_end=1202
  _globals['_SHUTDOWNRESPONSE']._serialized_start=1204
  _globals['_SHUTDOWNRESPONSE']._serialized_end=1222
  _globals['_INFERENCESERVICE']._serialized_start=1225
  _globals['_INFERENCESERVICE']._serialized_end=1561
# @@protoc_insertion_point(module_scope)
