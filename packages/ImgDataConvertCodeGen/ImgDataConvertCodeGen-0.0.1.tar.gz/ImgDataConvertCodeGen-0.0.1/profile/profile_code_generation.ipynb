{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a39ba89-0351-43ac-ad19-d69fed66aa2b",
   "metadata": {},
   "source": [
    "# Profiling Generating Conversion Code for In-memory Representations of Images using a Knowledge Graph of Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cb638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Assume the current working directory is where the this notebook file is located \n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(os.path.join(project_dir, \"src\"))\n",
    "# Alternatively you can install package directly from the Pypi. \n",
    "# %pip install imgdataconvertcodegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1275118e-0111-4669-8e2f-c8d750b9bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 21:02:13.865151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 21:02:16.868096: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "from imgdataconvertcodegen import get_conversion_code, _code_generator\n",
    "\n",
    "def clear_cache_in_code_generator():\n",
    "    _code_generator._cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1529cd-eacc-444e-b4e4-d46451415022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Graph with 553 nodes and 6472 edges.\n"
     ]
    }
   ],
   "source": [
    "print(_code_generator.knowledge_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c0bcd9e-bea3-496f-9048-db58762babd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3028 function calls (2998 primitive calls) in 0.002 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 105 to 2 due to restriction <2>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.001    0.001 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\astar.py:12(astar_path)\n",
      "      694    0.000    0.000    0.000    0.000 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:78(<lambda>)\n",
      "\n",
      "\n",
      "Converson code is \n",
      "import torch\n",
      "var_e9d7b6a25bd348ada1823b1778d9350d = torch.from_numpy(source_image)\n",
      "var_ad4cfcfd8dac4760b0fc5af9ac06fc1e = var_e9d7b6a25bd348ada1823b1778d9350d.permute(2, 0, 1)\n",
      "target_image = var_ad4cfcfd8dac4760b0fc5af9ac06fc1e.unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "clear_cache_in_code_generator()\n",
    "\n",
    "with cProfile.Profile() as profile:\n",
    "    source_image_desc = {\"lib\": \"numpy\"}\n",
    "    target_image_desc = {\"lib\": \"torch\", \"image_dtype\": 'uint8'}\n",
    "    code = get_conversion_code(\"source_image\", source_image_desc, \"target_image\", target_image_desc)\n",
    "    \n",
    "    \n",
    "    results = pstats.Stats(profile)\n",
    "    results.sort_stats(pstats.SortKey.TIME)\n",
    "    results.print_stats(2)\n",
    "\n",
    "    print(f'Converson code is \\n{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7f8b36-ad5b-451c-8a65-ff04fdc6efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2289 function calls (2288 primitive calls) in 0.002 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 75 to 2 due to restriction <2>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.001    0.001 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\astar.py:12(astar_path)\n",
      "      694    0.000    0.000    0.000    0.000 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:78(<lambda>)\n",
      "\n",
      "\n",
      "Converson code is \n",
      "import torch\n",
      "var_eedcd572407048478bbff65713475ed5 = torch.from_numpy(source_image)\n",
      "var_ba0abb1f0860438880feae1968ee8e3b = var_eedcd572407048478bbff65713475ed5.permute(2, 0, 1)\n",
      "actual_image = var_ba0abb1f0860438880feae1968ee8e3b.unsqueeze(0)\n",
      "\n",
      "The actual image matches the expected image.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "clear_cache_in_code_generator()\n",
    "with cProfile.Profile() as profile:\n",
    "    source_image = np.random.randint(0, 256, (20, 20, 3), dtype=np.uint8)\n",
    "    source_image_desc = {\"lib\": \"numpy\"}\n",
    "    target_image_desc = {\"lib\": \"torch\", \"image_dtype\": 'uint8'}\n",
    "    code = get_conversion_code(\"source_image\", source_image_desc, \"actual_image\", target_image_desc)\n",
    "    exec(code, globals())\n",
    "\n",
    "    results = pstats.Stats(profile)\n",
    "    results.sort_stats(pstats.SortKey.TIME)\n",
    "    results.print_stats(2)\n",
    "\n",
    "    print(f'Converson code is \\n{code}')\n",
    "    expected_image = torch.from_numpy(source_image).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    assert torch.equal(actual_image, expected_image), \"The actual image does not match the expected image.\"\n",
    "    print(\"\\nThe actual image matches the expected image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
