Metadata-Version: 2.1
Name: exxa
Version: 0.6.4
Summary: Exa - Pytorch
Home-page: https://github.com/kyegomez/Exa
License: MIT
Keywords: artificial intelligence,deep learning,optimizers,Prompt Engineering
Author: Kye Gomez
Author-email: kye@apac.ai
Requires-Python: >=3.10,<4.0
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.6
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Dist: loguru (>=0.5.3,<0.6.0)
Requires-Dist: torch (>2.0.0)
Project-URL: Documentation, https://github.com/kyegomez/Exa
Project-URL: Repository, https://github.com/kyegomez/Exa
Description-Content-Type: text/markdown

[![Multi-Modality](agorabanner.png)](https://discord.gg/qUtxnK2NMf)

# Exa
Boost your GPU's LLM performance by 300% on everyday GPU hardware, as validated by renowned developers, in just 5 minutes of setup and with no additional hardware costs.

-----

## Principles
- Radical Simplicity (Utilizing super-powerful LLMs with as minimal lines of code as possible)
- Ultra-Optimizated Peformance (High Performance code that extract all the power from these LLMs)
- Fludity & Shapelessness (Plug in and play and re-architecture as you please)

---

## ğŸ“¦ Install ğŸ“¦
```bash
$ pip3 install exxa
```
-----


## Usage






## ğŸ‰ Features ğŸ‰

- **World-Class Quantization**: Get the most out of your models with top-tier performance and preserved accuracy! ğŸ‹ï¸â€â™‚ï¸
  
- **Automated PEFT**: Simplify your workflow! Let our toolkit handle the optimizations. ğŸ› ï¸

- **LoRA Configuration**: Dive into the potential of flexible LoRA configurations, a game-changer for performance! ğŸŒŒ

- **Seamless Integration**: Designed to work seamlessly with popular models like LLAMA, Falcon, and more! ğŸ¤–

----

## ğŸ’Œ Feedback & Contributions ğŸ’Œ

We're excited about the journey ahead and would love to have you with us! For feedback, suggestions, or contributions, feel free to open an issue or a pull request. Let's shape the future of fine-tuning together! ğŸŒ±

[Check out our project board for our current backlog and features we're implementing](https://github.com/users/kyegomez/projects/8/views/2)


# License
MIT

# Todo

- Setup utils logger classes for metric logging with useful metadata such as token inference per second, latency, memory consumption
- Add cuda c++ extensions for radically optimized classes for high performance quantization + inference on the edge




