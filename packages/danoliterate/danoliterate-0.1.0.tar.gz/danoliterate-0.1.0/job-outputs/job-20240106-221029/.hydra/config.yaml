do: evaluate
outputs: job-outputs
evaluation:
  local_results: local-computations/result-db
  debug: false
  do_not_score_before: 2023-09-28-23-00
  rescore: false
  seed: 1887
  robustness_augment: true
  fairness_augment: false
  skip_unaugmented: false
  api_call_cache: local-computations/api-cache
model:
  batch_size: 32
  name: Constant Baseline
  inference:
    type: baseline
download_no_cache: false
model_paths:
  fasttext: local-models/lid.176.bin
  dsl3gram: local-models/dsl_3gram.klm
wandb:
  enabled: false
  entity: sorenmulli
  project: nlgenda
  artifact_cache: local-computations/wandb-cache.json
  cache_update: false
job_base_name: job
scenarios:
  hyggeswag:
    name: HyggeSwag
    path: sorenmulli/hyggeswag
    pre_prompt: 'Svar kun med bogstavet for den rigtige fortsættelse af sætningen

      # SÆTNING

      '
    post_prompt: '

      # SVARMULIGHEDER

      {options}

      # SVAR

      Den rigtige fortsættelse er mulighed '
    task:
      prompt_feature: ctx
      id_features:
      - source_id
      - ind
      type: default-mc-options
  dane:
    name: DaNE
    path: ScandEval/dane-mini
    pre_prompt: 'Fuldfør annotering af sidste eksempel i opgaven.

      Her er en lingvists arbejde med at annotere entiteter af typen ''{entity_str}''.
      {few_shot_str}


      # TEKST

      '
    post_prompt: '

      # ANNOTERING

      '
    dataset_split: val
    task:
      type: gpt-ner
      few_shot_format: '# TEKST

        {text}

        # ANNOTERING

        {annotated_text}'
      entity_types:
      - LOC: lokation
      - PER: person
      - ORG: organisation
      - MISC: diverse
      id_features: []
  da_gym_2000:
    name: Da. Gym 2000
    path: sorenmulli/da-gym-2000
    pre_prompt: '"{context}"


      Svar kun med bogstavet for den rigtige mulighed

      # SPØRGSMÅL

      '
    post_prompt: '

      # SVARMULIGHEDER

      {options}

      # SVAR

      Svaret er mulighed '
    task:
      type: default-mc-letter-context-and-options
      prompt_feature: question
      id_features:
      - task_title
      - index
  nordjylland_news:
    name: Nordjylland News
    path: sorenmulli/nordjylland-news-summarization-subset
    pre_prompt: 'Skriv et kort dansk resumé på én enkelt sætning af følgende tekst.

      # TEKST

      '
    post_prompt: '

      # RESUMÉ

      Et resumé på en sætning er: '
    task:
      type: default-answer-similarity
      prompt_feature: text
      answer_feature: summary
      id_features:
      - ind
  hashtag_twitterhjerne:
    name: '#twitterhjerne'
    path: sorenmulli/da-hashtag-twitterhjerne
    pre_prompt: 'Skriv et kort tweet på dansk, der besvarer nedenstående spørgsmål.
      Svar kun med tweetet.

      # TWEET MED SPØRGSMÅL

      '
    post_prompt: '

      # TWEET MED SVAR

      Et svar kunne være:'
    task:
      type: multi-answer-similarity
      prompt_feature: Question
      answer_feature: Answer
      id_features: []
  citizenship_test:
    name: Citizenship Test
    path: sorenmulli/citizenship-test-da
    pre_prompt: 'Svar kun med bogstavet for den rigtige mulighed

      # SPØRGSMÅL

      '
    post_prompt: '

      # SVARMULIGHEDER

      {options}

      # SVAR

      Svaret er mulighed '
    task:
      prompt_feature: question
      id_features:
      - origin
      - index
      type: default-mc-letter-options-showing
  da_cloze_self_test:
    name: Da. Cloze Self Test
    path: sorenmulli/da-cloze-self-test
    pre_prompt: '"'
    post_prompt: '"

      Erstat det maskerede ord i ovenstående tekst (markeret med ''<MASK>'') med et
      af følgende ord: {options}. Svar *kun* med det rigtige ord:

      Det rigtige ord var '
    task:
      type: cloze-showing-options
      id_features:
      - text-idx
      - cloze-idx
  angry_tweets:
    name: Angry Tweets
    path: ScandEval/angry-tweets-mini
    pre_prompt: 'Vurdér, om sentimentet i følgende tweet er ''positiv'', ''neutral''
      eller ''negativ''. Svar kun med et enkelt ord.

      # TWEET

      '
    post_prompt: '

      # SENTIMENT:

      Sentimentet var '
    dataset_split: val
    task:
      type: angry-tweets
      all_labels:
      - negative
      - neutral
      - positive
      id_features: []
databuild:
  type: prompt-answer
  hub:
    target: sorenmulli/prompt-answer-da
    push: true
    private: true
train:
  base_model: mistralai/Mistral-7B-v0.1
  reinit: false
  steps: 10000
  warmup_steps: 100
  resume: false
  optimizer: adamw_torch
  lr: 0.0001
  scheduler: cosine
  weight_decay: 0.01
  batch_size: 4
  accumulation: 4
  eval_batch_size: 8
  eval_accumulation: 1
  fp16: false
  bf16: true
  eval: true
  eval_every: 100
  save_every: 1000
  save_limit: 5
  log_every: 10
  use_sft: true
  lora:
    enabled: false
    r: 8
    alpha: 32
    dropout: 0.1
    target_modules:
    - q_proj
    - v_proj
  data:
    datasets:
    - uonlp/CulturaX:da
    - DDSC/dagw_reddit_filtered_v1.0.0
    seed: 1887
    text_col: text
    test_examples: 10000
    validation_examples: 1000
    context_tokens: 1024
    workers: 0
    buffer_size: 1000
    save_splits: false
    splits_path: local-computations/pretraining-splits
    debug_data: null
  debug: false
