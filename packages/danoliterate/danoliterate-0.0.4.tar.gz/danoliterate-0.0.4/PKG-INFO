Metadata-Version: 2.1
Name: danoliterate
Version: 0.0.4
Summary: Benchmark of Generative Large Language Models in Danish
Home-page: https://github.com/sorenmulli/danoliterate
Author: Søren Winkel Holm
Author-email: swholm@protonmail.com
License: Apache License 2.0
Description-Content-Type: text/markdown
Requires-Dist: pandas~=1.5.3
Requires-Dist: datasets~=2.14.5
Requires-Dist: transformers~=4.36.1
Requires-Dist: torch~=2.1.1
Requires-Dist: safetensors~=0.3.3
Requires-Dist: matplotlib~=3.8.0
Requires-Dist: simple-term-menu~=1.6.1
Requires-Dist: augmenty~=1.4.4
Requires-Dist: seqeval~=1.2.2
Requires-Dist: levenshtein~=0.23.0
Requires-Dist: nltk~=3.8.1
Requires-Dist: absl-py~=2.1.0
Requires-Dist: evaluate~=0.4.0
Requires-Dist: rouge_score~=0.1.2
Requires-Dist: bert_score~=0.3.13
Requires-Dist: gensim~=4.3.2
Requires-Dist: danlp~=0.1.2
Requires-Dist: huggingface_hub~=0.19.4
Requires-Dist: hydra-core~=1.3.2
Requires-Dist: hydra-colorlog~=1.2.0
Requires-Dist: omegaconf~=2.3.0
Requires-Dist: gitpython~=3.1.37
Requires-Dist: black~=23.7.0
Requires-Dist: isort~=5.12.0
Requires-Dist: mypy~=1.5.1
Requires-Dist: pylint~=2.17.5
Requires-Dist: pandas-stubs~=2.0.3
Requires-Dist: types-tqdm~=4.66.0
Requires-Dist: types-requests~=2.31.0
Provides-Extra: full
Requires-Dist: pypdf~=3.16.1; extra == "full"
Requires-Dist: fasttext-wheel~=0.9.2; extra == "full"
Requires-Dist: peft~=0.5.0; extra == "full"
Requires-Dist: scipy~=1.11.3; extra == "full"
Requires-Dist: spacy~=3.5.4; extra == "full"
Requires-Dist: beautifulsoup4~=4.12.2; extra == "full"
Requires-Dist: trl~=0.7.4; extra == "full"
Requires-Dist: wandb~=0.16.6; extra == "full"
Requires-Dist: deepspeed~=0.12.4; extra == "full"
Requires-Dist: sentencepiece~=0.1.99; extra == "full"
Requires-Dist: accelerate~=0.23.0; extra == "full"
Requires-Dist: google-cloud-aiplatform~=1.38.1; extra == "full"
Requires-Dist: openai~=0.28.1; extra == "full"
Requires-Dist: anthropic~=0.21.3; extra == "full"
Requires-Dist: groq==0.4.2; extra == "full"

# Are LLMs Danoliterate?

A benchmark for Generative Large Language Models in Danish. 
To see results and and get more details, check out the leaderboard site:

<p align="center">
<a href="https://danoliterate.compute.dtu.dk/">danoliterate.compute.dtu.dk</a>
</p>

The project is maintained by Søren Vejlgaard Holm at DTU Compute, supported by the Danish Pioneer Centre for AI and with most of the work done as part of the Master's thesis [''Are GLLMs Danoliterate? Benchmarking Generative NLP in Danish''](https://sorenmulli.github.io/thesis/thesis.pdf) supervised by Lars Kai Hansen from DTU Compute and Martin Carsten Nielsen from Alvenir.

## Installation

The package has been developed and used with Python 3.11.
To install the package in a base version, enabling model execution, install
```
pip install danoliterate
```
*Note:* Some features need a full install to run:
```
pip install danoliterate[full]
```

## Usage

See options with
```bash
python -m danoliterate do=evaluate
```

A typical use would be to run your own model hosted on the Huggingface Hub on a scenario, for example the Citizenship Test Scenario (see [the frontend](https://danoliterate.compute.dtu.dk/Scenarios) for scenario descriptions).
Skip the line `scenarios=` to make it run on all scenarios instead.
```bash
python -m danoliterate do=evaluate\
    scenarios="citizenship-test"\
    model.name="MyLittleGPT"\
    model.path="hf-internal-testing/tiny-random-gpt2"\
    evaluation.local_results="./my-result-db"
```

Now, you could share the resulting JSON placed in `my-result-db` to get it included in the Danoliterate benchmark, or you can satisfy your curiosity and score it yourself
```bash
# Calculates scoring metrics
python -m danoliterate do=score\
    evaluation.local_results="./my-result-db"
# Prints them for you
python -m danoliterate do=report\
    evaluation.local_results="./my-result-db"
```

## Contact
Please reach here using GitHub issues or on mail to Søren Vejlgaard Holm either at [swiho@dtu.dk](mailto:swiho@dtu.dk) or [swh@alvenir.ai](mailto:swh@alvenir.ai).
