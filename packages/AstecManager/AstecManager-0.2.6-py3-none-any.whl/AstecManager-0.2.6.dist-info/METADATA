Metadata-Version: 2.1
Name: AstecManager
Version: 0.2.6
Summary: This package creates a management system to run the ASTEC algorithms for developmental biology live imaging. 
Home-page: https://gite.lirmm.fr/bgallean/astecmanagerelease
Author: Benjamin GALLEAN
Author-email: benjamin.gallean@crbm.cnrs.fr
Project-URL: Bug Tracker, https://gite.lirmm.fr/bgallean/astecmanagerelease/-/issues
Classifier: Programming Language :: Python :: 3.10
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Requires-Dist: nibabel ==5.2.1
Requires-Dist: numpy ==1.26.4
Requires-Dist: scipy ==1.12.0
Requires-Dist: scikit-image ==0.22.0
Requires-Dist: importlib-resources ==6.3.0
Requires-Dist: pandas ==2.2.1
Requires-Dist: seaborn ==0.13.2
Requires-Dist: tifffile ==2024.2.12
Requires-Dist: ezomero ==2.1.0
Requires-Dist: colorama ==0.4.6
Requires-Dist: matplotlib ==3.8.3
Requires-Dist: h5py ==3.10.0
Requires-Dist: dataclasses ==0.6
Requires-Dist: morphonet ==2.2.11
Requires-Dist: Markdown ==3.5.2
Requires-Dist: pydrive2 ==1.19.0
Requires-Dist: pillow ==9.2.0
Requires-Dist: python-docx ==1.1.0
Requires-Dist: opencv-python ==4.9.0.80

## This library has been created to automatize and help users to segment using ASTEC software. 
On top of the ASTEC integration the tool include multiple addiotional features :
* Data enhancement (contour computation, smoothing, ...)
* Data Management (integration of OMERO data manager, automatic compression, automatic generation of metadatas , generation of embryo identification card)
* Analyse the data generated through ASTEC pipeline (using different graphs)
* Integrated generation of properties (ASTEC properties , naming )


# Table of contents
1. [Installation](#install)
2. [Update](#update)
3. [Template files link](#template-files-link)
4. [Fusion](#fusion)
5. [Fusion parameters tuning](#fusion-parameters-test)
6. [Fusion final run](#fusion-final-run)
7. [Contours (optional)](#contours-_optional_)
8. [First time point segmentation](#first-time-point-segmentation)

## Install

The first step to use this tool will be to install the Conda package manager.
You can find a guide to install conda [here](/https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html) 

Now that conda is installed,  open a new terminal, and type the following lines : 

`conda create -n AstecManager -c conda-forge python=3.10 zeroc-ice omero-py` \
`conda activate AstecManager` \
`pip install AstecManager`

Those lines will install the creation a conda environment to use the package , and install the package and its dependencies into the environment. It includes the installation of the necessary Python version.

To be able to run the different algorithms of ASTEC pipeline, you will need to install ASTEC package and its dependencies. To do so , please follow [this link](https://astec.gitlabpages.inria.fr/astec/installation.html).

On top of that, in order to automatically  name a new embryo during the pipeline , you will need to install ASCIDIAN package , and its dependencies. To do so , please follow [this link](https://astec.gitlabpages.inria.fr/ascidian/installation.html).

## Template files link 

The tool uses parameters files to run each of the different steps. Those files are available as templates following [this link](https://seafile.lirmm.fr/d/5ceffaa28deb4c109066/).

Please download the corresponding file for the step you are planning to run , and edit it to your needs.

Parameters file link by step : 

- [Import raw datas from microscope computer](https://seafile.lirmm.fr/f/e2320ea88f694f4eb5e0/?dl=1)
- [Perform a test fusion](https://seafile.lirmm.fr/f/fc8ee1ba0ed04c469a4a/?dl=1)
- [Perform the final fusion](https://seafile.lirmm.fr/f/cfe0b273d2e8454c9b1a/?dl=1)
- [If needed , generate INTRAREG movie from fusion images](https://seafile.lirmm.fr/f/5c43780e4e8c4ef7b199/?dl=1)
- [If needed, generate a video from INTRAREG movie](https://seafile.lirmm.fr/f/e773aef8e4074fc28ec9/?dl=1)
- [After generating backgrounds , compute contour images](https://seafile.lirmm.fr/f/4e18fc2897e74e6c8e9a/?dl=1)
- [Segmentation of the first time point](https://seafile.lirmm.fr/f/15573876ef7b46fea4ce/?dl=1)
- [Downscaling for the segmentation tests](https://seafile.lirmm.fr/f/7960d9c592604ca4a85c/?dl=1)
- [Segmentation test runs](https://seafile.lirmm.fr/f/f86682d64c2d48898854/?dl=1)
- [Final segmentation run](https://seafile.lirmm.fr/f/1366fb5cec23448fb17e/?dl=1)
- [Automatic naming](https://seafile.lirmm.fr/f/b987a58755ca4f7e9e7f/?dl=1)

OMERO communication (download , upload):

- [Link to OMERO authentification file template](https://seafile.lirmm.fr/f/a751b5c13afd4c2fb36a/?dl=1) 
- [Link to download a specific OMERO dataset](https://seafile.lirmm.fr/f/e4fbf47de7d2489ca5cd/?dl=1)
- [Link to download a complete OMERO project(embryo)](https://seafile.lirmm.fr/f/bf93946f0f1349ac9b92/?dl=1)
- [Link to upload a specific image folder to OMERO dataset](https://seafile.lirmm.fr/f/2758893a3cc742cf84ce/?dl=1)
- [Link to upload a complete embryo folder to OMERO project](https://seafile.lirmm.fr/f/acd17fdcd47e41e2bfb0/?dl=1)


## Update

Often, the tool will be updated to add features, and debug the existing ones. 

* To update the tool, you can simply start a terminal and run :

`conda activate AstecManager` \
`pip install AstecManager --upgrade`

## Data Manager Integration

To store the data for further work and archives , the team uses a data manager called OMERO.
In the following pipeline, you will be able to upload or download the different data produced to OMERO , automatically or manually.

In order to upload or download, you first need to create a file on your computer, somewhere no one can access and that you should not share.

The file should contain the following lines : 

```
host=adress.to.omero.instance
port=omero.port (usually 4064)
group=your team group
secure=True
java_arg=java
login=your omero login
password=your omero password
```

Save this file and store its path so you can access it when needed.

A template for the configuration file can be found [here](https://seafile.lirmm.fr/f/a751b5c13afd4c2fb36a/?dl=1)


## Fusion


The most crucial part of this process is combining the images, and it needs to be done quickly. You should begin this step right after copying the large Raw Images, and try to finish it as soon as you can.

These Raw Images are very large, roughly 3 gigabytes each. This means that if you're working with one time point, it will use up about 12 gigabytes of computer memory. Think about it this way: if you're dealing with an embryo at 300 different time points and you have multiple channels of images, your Raw Images folder could take up as much as 2 to 3 terabytes of space on your computer's hard drive.

Additionally, the Raw Images often have a significant amount of background information, which takes up a lot of memory. This background includes unnecessary data.

The fusion step is designed to address the problems we've just talked about:

- It keeps the most valuable information from each camera angle to create an isotropic image. An isotropic image means that it has the same characteristics, like intensity, across all regions.

- It reduces the memory needed for a single time point from around 12 gigabytes to a more manageable 500 megabytes.

- It also trims the image around the embryo, cutting out the excessive background and keeping only the essential information.

For more details about this step , please follow [this link](https://astec.gitlabpages.inria.fr/astec/astec_fusion.html#fusion-method-overview)

It's advised to split fusion in 2 steps 
* A test step where you will find the best parameters for this specific dataset.
* A production step where you will apply the best parameters to the complete dataset.

* Your folder hierarchy should look like this, before starting the fusion

``` 
     embryo name
         └───RAWDATA
             │───stack_0_channel_0_obj_left
             │───stack_0_channel_0_obj_right
             │───stack_1_channel_0_obj_left
             │───stack_1_channel_0_obj_right
             └───... (more if you have another channel)
             
```

#### Fusion parameters test
The fusion parameters test is a needed step , considering the high number of parameters needed for fusion , we can't take the time to try them one by one, on a large time sequence.

The test step is split in 2 sub steps : 

- 1st , a test fusion using the parameter set that is usually correct for our data
- If it's not working, 4 sets of parameter that usually are the ones that may differ 
- If it's still not working , you're invited to explore the fusion parameters documentation [here](https://astec.gitlabpages.inria.fr/astec/astec_parameters.html#astec-fusion-parameters)

To start the fusion test step , please download the template parameters file from this [link](https://seafile.lirmm.fr/f/fc8ee1ba0ed04c469a4a/?dl=1) , and save it to your embryo folder. Your file architecture should look like this : 
``` 
     embryo name
     │   └───RAWDATA
     │       │───stack_0_channel_0_obj_left
     │       │───stack_0_channel_0_obj_right
     │       │───stack_1_channel_0_obj_left
     │       │───stack_1_channel_0_obj_right
     │       └───... (more if you have another channel)
     └── run_test_fusion.py
```

And then , you should edit it to bind the good parameter for your embryo : 


```
parameters["embryo_name"] = '<name>' : replace <name> with the name of your embryo folder
parameters["begin"]=1 : for test, should be set to the only time point , and be the same than "end"
parameters["end"]=1 : for test, should be set to the only time point , and be the same than "begin"
parameters["user"] = '<UI>' : for every step , will be used to store an history of the data,<UI>  should be replaced by experimentator name and surname first letters
```

Setting up those parameters should be enough to start the first fusion test. In order to do so , open a terminal in the embryo folder ;

``` 
     embryo name   <-- Open a terminal here
     │   └───RAWDATA
     │       │───stack_0_channel_0_obj_left
     │       │───stack_0_channel_0_obj_right
     │       │───stack_1_channel_0_obj_left
     │       │───stack_1_channel_0_obj_right
     │       └───... (more if you have another channel)
     └── run_test_fusion.py
```

and then you can start the process with those commands : 

`conda activate AstecManager` \
`python3 run_test_fusion.py` 

This step will take a few minutes to run, and will generate a fusion image in this directory : 
``` 
     │──embryo name
     │    │───RAWDATA
     │    │    └─── ...
     │    └───FUSE
     │        └─── FUSE_01_test
     │           │─── embryo_name_fuse_t040.nii
     │           └─── ... 
     └─ run_test_fusion.py
``` 
###### Verify fusion 

Now that you generated the first fusion test , you need to verify the quality of the fusion. For this , we have to visually check if the generated image is correct, this can be done using
Fiji [(here is a link to a documentation on how to use Fiji)](https://imagej.net/tutorials/). Here is an example of what a wrong fusion rotation may look like , which is the first error you can find : 


| Example of fusion with correct rotation | Example of fusion with wrong rotation |
|:---------------------------------------:|:-------------------------------------:|
|  ![](doc_images/good_orientation.png)   | ![](doc_images/wrong_orientation.png) |

If the rotation seems good , you will need to check in the temporary images generated by the fusion , if the different steps were well parametered


Inside each fusion folder , you can find a folder called "XZSECTION_XXX" where "XXX" is the time point fused. 
Inside the folder , you will see 4 images : 

- embryoname_xyXXXX_stack0_lc_reg.mha
- embryoname_xyXXXX_stack0_lc_weight.mha
- embryoname_xyXXXX_stack0_rc_reg.mha
- embryoname_xyXXXX_stack0_rc_weight.mha
- embryoname_xyXXXX_stack1_lc_reg.mha
- embryoname_xyXXXX_stack1_lc_weight.mha
- embryoname_xyXXXX_stack1_rc_reg.mha
- embryoname_xyXXXX_stack1_rc_weight.mha

|       Left-cam stack 0 reg + weighting       |       Stack cameras matching        |       Stack 0 and 1 matching       |
|----------------------------------------------|-------------------------------------|------------------------------------|
| ![](doc_images/fuse_extraction_lcstack0.png) | ![](doc_images/leftandrightcam.png) | ![](doc_images/stacksmatching.png) |

On the left image  of the table you can see that the registration image (left), is matching the weighting used for the computation. It means that the weighting is correct.
On the middle image , you can see that the left camera and right camera of the same stack is matching.
On the right image, you can see that both stacks images are matching , so the fusion will be correct.

If the xzsection registration (the images containing <_reg> inside their names) are matching , and the weighing seem to be coherent , you can skip to final fusion step. 

If the xzsection registration (the images containing <_reg> inside their names) do not seem to match , either withing the same stack , or between the 2 different stacks, it means that you will need to explore 2 more parameters.
We made this step easier by creating a mode that tests automatically all 4 possibles combination for the parameters.

Modify your "run_test_fusion.py" file to change this line : 

```
manager.test_fusion(parameters,parameter_exploration=False)
```

to 

```
manager.test_fusion(parameters,parameter_exploration=True)
```

and then start your test step again , the same way you started it before : 

`conda activate AstecManager` \
`python3 run_test_fusion.py` 


if the xzsection weighting is not matching the image correctly, you may need to change the weighting function used in the fusion computation. In order to do this , modify your "start_fusion_test.py" file to add this line:
```
parameters["fusion_weighting"]= set it to "'uniform'" , "'ramp'" or "'corner'"
```
BEFORE the final line : 

```
manager.test_fusion(...
```

When you changed the file , you can run the fusion test again

`conda activate AstecManager` \
`python3 run_test_fusion.py` 

#### Final fusion

Now that you have finished the fusion test step , found the parameters that gives you a good result , and verified them on the fusion image itself + the temporary images generated in the XZSECTION
you can start the final fusion by downloading the parameter file here : 

The parameter find can be found [here](https://seafile.lirmm.fr/f/cfe0b273d2e8454c9b1a/?dl=1)

Save it to the embryo folder, in the same location where you saved the test file , and start by editing it : 

```
parameters["embryo_name"] = '<name>' : replace <name> with the name of your embryo folder
parameters["begin"]=0 : for fusion, should be set to the first time point of the sequence
parameters["end"]=100 : for fusion, should be set to the last time point of the sequence
parameters["user"] = '<UI>' : for every step , will be used to store an history of the data,<UI>  should be replaced by experimentator name and surname first letters
parameters["number_of_channels"] = 1 : change this to the number of channel in the raw images acquisition. The same fusion will be applied to all channels
parameters["omero_config_file"]= '/path/to/the/omero/config/file' : if you want to upload the result images of the fusion, you can enter the path to your omero configuration file. If you didn't create the omero
file , please read the "Data Manager Integration" section of this documentation. After fusion, a new dataset will be created in the embryo project on OMERO (created if it doesn't exist) , and will contain all of the fusion images
```

Finally , you will need to modify the following lines : 

```
parameters["fusion_strategy"]= 'hierarchical-fusion'
parameters["acquisition_orientation"]= 'left'
```

If the fusion test ran fine during the test step , and you didn't need to start the 4 fusion test exploration, you can leave the lines as they are.
If not , please update them with the parameters that worked the best among the 4 tests fusion. 

  - if the FUSE_01_left_direct was the correct one , change the parameters to :
    ```
    parameters["fusion_strategy"]= 'direct-fusion'
    parameters["acquisition_orientation"]= 'left'
    ```
  - if the FUSE_01_left_hierarchical was the correct one , change the parameters to :
    ```
    parameters["fusion_strategy"]= 'hierarchical-fusion'
    parameters["acquisition_orientation"]= 'left'
    ```
  - if the FUSE_01_right_direct was the correct one , change the parameters to :
    ```
    parameters["fusion_strategy"]= 'direct-fusion'
    parameters["acquisition_orientation"]= 'right'
    ```
  - if the FUSE_01_right_hierarchical was the correct one , change the parameters to :
    ```
    parameters["fusion_strategy"]= 'hierarchical-fusion'
    parameters["acquisition_orientation"]= 'right'
    ```

And finally , if you added other parameters to the test file (for example weighing method modification) , please provide the corresponding lines in the final fusion file too. 

When all of this is ready , you can start the final fusion. Open a terminal in the embryo folder and run the following lines 

`conda activate AstecManager` \
`python3 run_final_fusion.py` 

The computation of the fusion step will take a few hours, depending on the number of time point in the embryo , and the number of channels to fuse. When finished , multiple new data will be generated : 
First, you can delete the following files and folders :
- folder FUSE/FUSE_01_left_direct
- folder FUSE/FUSE_01_left_hiearchical 
- folder FUSE/FUSE_01_right_direct 
- folder FUSE/FUSE_01_right_hiearchical

The final folder architecture after fusion will be this one :

``` 
experiment folder 
└───embryo specie
    │──embryo name
    │   │───analysis
    │   │    └─── fusion    
    │   │          └─── fusion_movie.mp4
    │   │───INTRAREG
    │   │    └─── INTRAREG_01_TEST
    │   │          └─── MOVIES
    │   │               └─── FUSE
    │   │                   └─── FUSE_01
    │   │                       └─── embryo_name_intrareg_fuse_tbegin-tend_xy0XXX.mha
    │   │───RAWDATA
    │   │    └─── ...
    │   └───FUSE
    │       └─── FUSE_01
    │          │─── embryo_name_fuse_t000.nii
    │          │─── embryo_name_fuse_t001.nii
    │          └─── ... 
```

### Fusion verification
To verify the final fusion , you can use the movie generated by the code. This movie presents the same slice of the fusion images through time.
By looking at the movie , the user can make sure that all the time points were fused correctly. 

You can find the movie in the following folder : "embryo_name/analysis/fusion/fusion_movie.mp4"

If, after the final fusion , the fusion_movie.mp4 file has not been generated , you can find this movie as an image in the following folder : "embryo_name/INTRAREG/INTRAREG_01_TEST/MOVIES/FUSE/FUSE_01/" . 

After opening the image in Fiji , you will see that it is a slice of the fusion image , where the Z axis (the slider at the bottom of image) correspond to this slide through time. 
To validate the fusion through time , make sure that the image orientation , and the fusion registration remains coherent, even if the embryo is slightly different, or may have moved between the 2 times.


## Contours _(optional)_

The following section is a documentation about the generation of additional input images used for the segmentation pipeline. Most of the segmentations errors we may face come from the external part of the embryo (cells in contact with the background)

Using a deep learning tool trained by the MorphoNet team, we are able to generate a mask image , separating the background from the embryo . 
This tool need a powerful computer to run , and should not be used on the user machine.

In the team , we use a computer called loki. To get access to Loki using ssh , first ask the team.

To start the computation  , you first need to get the identifier of your dataset on omero.
For this goes to omero , find your project and the dataset (green folder) , and look at the properties on the right.
You will find a line called "Dataset id : ". Copy the number on the right 

##### Run in a terminal , line by line the following :


`ssh loki.crbm.cnrs.fr` \
`conda activate morphodeep` \
`cd /data/MorphoDeep/morphodeep/morphodeep/Process/` \
`python3 Compute_Background_From_Omero.py -d id_dataset_omero -m FusedToBackground`

After the computation , you will find a new dataset inside the omero project , called Background_name_of_fusion_dataset

There is no troubleshooting for this section , if you have a problem , you need to find a team member.

When the background computation is done , and all the images are available on the data manager, you will have to download them on the computer that will compute the next steps. 
In order to do so , please download the following parameters file :  [here](https://seafile.lirmm.fr/f/e4fbf47de7d2489ca5cd/?dl=1) , in any folder. 

Please edit it : 
```
parameters["omero_authentication_file"] = None : replace None by the omero config you created before , if you didn't please refer to section "Data Manager Integration"
parameters["project_name"] = "" : write the name of the omero project of your dataset between the " " (should be the embryo name) 
# DATASET NAME ON OMERO
parameters["dataset_name"] = "" : write the name of the omero dataset of your dataset between the " " (should be BACGROUND_FUSE_01) 
# PATH OF THE OUTPUT FOLDER
parameters["destination_folder"] = "" : write the path to the download folder. For backgrounds , shound be ( /path/to/embryo_name/BACKGROUND/<name of the omero dataset>/ )
```

Open a terminal where the download parameters file is , and start the download by running : 

`conda activate AstecManager` \
`python3 download_dataset_from_omero.py`

When the download has finished, you should fine the images in the folder corresponding to <parameters["output_folder"]> 

With the background/embryo mask images downloaded , you are now able to generate the contour images, used for segmentation preprocessing.

The following code will automatically compute the contours images, that will be used later. The contours are computed by smoothing and increasing the thickness of the edge between background and embryo.

Please download the following parameters file [here](https://seafile.lirmm.fr/f/4e18fc2897e74e6c8e9a/?dl=1) , and store it inside your embryo folder

Edit the file like this : 

```
parameters["embryo_name"] = "" : Name of your embryo folder
parameters["EXP_BACKGROUND"] = "BACKGROUND_FUSE_01" : replace <Background_FUSE_01> with the name of the folder where you downloaded background images (if it's different)
parameters["omero_authentication_file"] = None : replace None by the omero config you created before , if you didn't please refer to section "Data Manager Integration" if you want to upload contours to the data manager automatically
parameters["user"] = "UI" : for every step , will be used to store an history of the data,<UI>  should be replaced by experimentator name and surname first letters
```

For a normal usage , computers are generated on full resolution fusion images and with a specific normalisation applied to contour image instensities , that you can find in those lines : 

```
parameters["normalisation"] = 1000 # Normalisation of intensities in the output image (contour intensities will be in [0:normalisation]
parameters["resolution"]=0.3 # Resolution of the background input images , and the output contour generated
```

Please update the corresponding values if you know what you are doing.

When all the parameters are written , you can open a terminal where the download parameters file is , and start the generation by running : 

`conda activate AstecManager` \
`python3 compute_contours.py`

The code will create this folder "/embryoname/CONTOUR/CONTOUR_RELEASE_3/"  ,where the contour image are stored

There is no troubleshooting for this section , if you have a problem , you need to find a team member

## First time point segmentation 

The segmentation process for our data is based on the propagation. Using the previous time step segmentation , the algorithm compute new segmentations , and then detect the cell divisions ( or not ) to compute the lineage. 
In order to start the process , it is needed to have a first time point segmentation, that SHOULD be empty of any segmentation errors. 
We now have 2 systems to compute the first time point segmentation :  

### MARS 

MARS is the standard segmentation algorithm used for the first time point with our data.
To start MARS algorithm , please download the parameter file [here](https://seafile.lirmm.fr/f/15573876ef7b46fea4ce/?dl=1) and store it in your embryo folder

Edit it : 

```
parameters["embryo_name"] = "name": replace <name> with the name of your embryo folder
parameters["begin"]=1 : replace '1' with the first time point of the fusion sequence
parameters["end"]=1 :  replace '1' with the first time point of the fusion sequence (HAS TO BE EQUAL TO parameters["begin"])
parameters["resolution"] = 0.3 : Only change this if you are working in half resolution (it should be 0.6 with half resolution)
parameters["EXP_FUSE"] = '01' : Name of the fusion exp for the intensity images 
parameters["use_contour"] = True : Should be <True> to use the contour for the segmentation of the first time point, <False> otherwise 
parameters["apply_normalisation"] = True : Should be <True> if you want to normalize input images intensities between [0;normalisation], <False> otherwise 
parameters["normalisation"] = 1000 # if apply_normalisation is True , value of normalisation applied
parameters["user"]= 'UI' : for every step , will be used to store an history of the data,<UI>  should be replaced by experimentator name and surname first letters

```

Open a terminal in your embryo folder , and start the MARS by running : 

`conda activate AstecManager` \
`python3 run_mars.py`

The code will generate 2 segmentations of the first time point, the difference between the being how the intensities of the input images are integrated together to get an enhanced images. 

The embryo folder hierarchy should look like this : 

``` 
experiment folder 
└───embryo specie
    │──embryo name
    │   │───SEG
    │   │    │─── SEG_mars_add
    │   │    │   │─── LOGS
    │   │    │   └─── embryo_name_mars_t000.nii
    │   │    │   
    │   │    │─── SEG_mars_max
    │   │    │   │─── LOGS
    │   │    │   └─── embryo_name_mars_t000.nii
    │   │───INTRAREG
    │   │    └─── ...
    │   │───RAWDATA
    │   │    └─── ...
    │   └───FUSE
    │       └─── ... 
```

To compare the two MARS segmentations generated by this step , follow the steps detailed in the [First time point verification section](#firstverif) for each segmentation.

### MorphoNet Cellpose integration 

MorphoNet application has acquired a new plugin , taking in input the intensity image (fusion) of a time point , and generating a segmentation using a deep learning model.

To install MorphoNet Standalone, please refer to the MorphoNet documentation for application by [clicking here](https://morphonet.org/help_standalone) 

Then add the intensity images to your MorphoNet local datasets following the documentation [here](https://morphonet.org/help_standalone#add_local) 

Use the MorphoNet curation module to generate a segmentation from your intensity images. To use the curation menu , please read the documentation [here](https://morphonet.org/help_app?menu=curations)

The documentation for CellPose plugin, used to generate the segmentations , can be found [here](https://morphonet.org/help_app?menu=curations#cellpose)

After generating the segmentation , you can curate all the errors using the plugins detailed [here](https://morphonet.org/help_curation) , or follow the curation example documentation [here](https://morphonet.org/help_curation)


<h3 id="firstverif"> First time point verification </h3>

The only way to verify the quality of the segmentation generated by the first time point segmentation algorithm chosen is to import this data in MorphoNet, and find the different errors.

#### Import of the data in MorphoNet 

This section is only needed if you used MARS algorithm to generate the segmentation. The idea is to import both segmentation (mars_add and mars_max) as MorphoNet local datasets.  

To install MorphoNet Standalone, please refer to the MorphoNet documentation for application by [clicking here](https://morphonet.org/help_standalone) 

You can find a documentation in MorphoNet help to create a local dataset [here](https://morphonet.org/help_standalone#add_local)

#### Verification of the first point and curation

After importing the dataset in MorphoNet application , locate the different errors in each of the segmentation generated, and find the one with the least errors.

When the segmentation is chosen , curate it using the documentation example found [here](https://morphonet.org/help_curation)


### First time point storage 

When the first time point is curated, please store it in a new folder inside the embryo folder. This new folder should be called MARS, and contain only the mars image.

Here is the architecture of the embryo folder at this step : 

``` 
experiment folder 
└───embryo specie
    │──embryo name
    │   │───SEG
    │   │    └─── ...
    │   │───MARS
    │   │    └─── embryo_name_mars_t000.nii
    │   │───INTRAREG
    │   │    └─── ...
    │   │───RAWDATA
    │   │    └─── ...
    │   └───FUSE
    │       └─── ... 
```
## Data downscaling _(optional)_ : Fusions , Contours and First time point
