Metadata-Version: 2.1
Name: celi-framework
Version: 0.0.0
Summary: Controller-Embedded Language Interactions - facilitates the entire lifecycle of document processing, from pre-processing and embedding to post-monitoring and quality assessment.
Home-page: https://github.com/x3n0cr4735/celi
License: Apache 2.0
Author: Jan-Samuel Wagner
Author-email: jwab@genmab.com
Requires-Python: >=3.10,<4.0
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: Other/Proprietary License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Typing :: Typed
Requires-Dist: bert-score (>=0.3.13)
Requires-Dist: evaluate (>=0.4.1)
Requires-Dist: llama-index (>=0.10.23)
Requires-Dist: llama-index-vector-stores-chroma (>=0.1.6,<0.2.0)
Requires-Dist: py-llm-core (>=2.8.2)
Requires-Dist: pymongo (>=4.6.2)
Requires-Dist: python-dotenv (>=1.0.0)
Requires-Dist: requests-cache (>=1.2.0)
Project-URL: Repository, https://github.com/x3n0cr4735/celi
Description-Content-Type: text/markdown

# CELI: Controller-Embedded Language Interactions
CELI (pronounced like "Kelly") is a versatile framework designed to harness the power of large language models (LLMs) to automate a wide range of knowledge-work tasks. 

This includes, but is not limited to, drafting massive/complex documents, conducting rigrous literature reviews, creating many tables in parallel, and cleaning datasets methodically. CELI is engineered to support the entire lifecycle of automation tasks, from initial data preprocessing to embedding, to post-processing and quality control. Among other use cases, engineers can utilize CELI to swiftly develop enterprise-embedded applications tailored to specific stakeholder needs, such as compliance with style-guides (language, formatting), adherence to rigrous methodologies, and extensive auditing.

## Overview

CELI comprises several modules, each responsible for a distinct part of the document processing workflow:

- **Processor**: Manages and orchestrates the drafting of documents using language models, acting as the core of the CELI system.
- **Monitor**: Observes and evaluates the performance of the ProcessRunner, ensuring quality and efficiency in automated tasks.
- **Tasks**: Each CELI workflow is a user-defined list of tasks that instruct the agent how to run.
- **Tools**: Tools provide mechansims for CELI to interact iwth the world.  Tools can be customized for the use case.

These components are in the CELI 'celi-framework.core' package

CELI contains experimental versions of several additional tools that can help develop new use cases more quickly and accomplish different tasks:
- **Pre-Processor**: Converts DOCX documents to a clean Markdown format, making them primed for embedding.
- **Embeddor**: Embeds pre-cleaned text data from source documents, preparing it for machine learning models and data analysis.
- **Mapper**: Focuses on pre-computing mappings between document content, enhancing the efficiency of the embedding process.
- **Post-Monitor**: Evaluates the execution of processes, standardizing task labels and analyzing task quality variations.
- **Mechanic**: Fixes issues identified by the post-monitor, ensuring the system adapts and improves over time.

These components are in `celi-framework.experimental`.

Additionally, `celi-framework.examples` contains examples for applying CELI to different use cases.

## Key Features

- **Automated Document Processing**: From initial pre-processing to final quality assessment, CELI automates the entire document processing workflow.
- **Quality and Efficiency**: Embedded monitoring and post-monitoring ensure the highest quality outputs and process efficiency.
- **Flexibility**: CELI's modular design allows for customization and scalability, accommodating a wide range of document processing needs.
- **Advanced Embedding Techniques**: Utilizes OpenAI's embeddings to transform text data into formats suitable for machine learning applications.

## Getting started

To get an idea of what CELI can do, we have prepackaged an example use case.  In this case, we will have CELI write a wiki page on a topic given an example page and a set of references.

### Install CELI

First, install celi using PIP with the following command:

`pip install celi`

You can also clone the repo and install CELI from source.  See [Running CELI from Source] below.

### Set up a mongo DB server to store documents

CELI uses Mongo to cache LLM responses, store documentsm inspect runs.  If you already have a Mongo server running, you can point Celi to it and it will create a new database called 'celi'.  If not, you can quickly spin up a local mongo server using this docker command:

`docker run --name mongodb -p 27017:27017 -d mongo`

### Configure your environment

The main script for CELI loads some configuration from environment variables.  The [`python-dotenv`](https://pypi.org/project/python-dotenv/) package is used to load these files from a file called `.env` in the current directory.

Create a .env file with an example configuration, copying the file below and substituting in your OpenAI API key.  If you have the repo cloned, you can copy the .env.example file.

    OPENAI_API_KEY=<REPLACE WITH YOUR OPENAI API KEY>
    OUTPUT_DIR=target/celi_output
    DB_URL=mongodb://localhost:27017/
    EXTERNAL_DB=True
    NO_MONITOR=True
    JOB_DESCRIPTION=celi-framework.examples.wikipedia.job_description.job_description
    TOOL_CONFIG_JSON=celi-framework/examples/wikipedia/example_config.json
    PARSER_MODEL_CLASS=llm_core.parsers.OpenAIParser
    PARSER_MODEL_NAME=gpt-3.5-turbo-16k

### Run the example use case

Once you have the steps above done, you can test your setup by running

`python -m celi-framework.main`

This example use case uses the wikipedia page for Led Zeppelin as the example document, and then creates a new wiki page for the Jonas Brothers based on the references cited from their wikipedia page.  The result will be put in the `target/drafts` directory.

## Defining a use case for CELI

CELI is an agent framework designed to carry out a series of tasks on a set of documents or document sections.  When CELI executes, it can use tools to accomplish those tasks.  When you configure a new use case for CELI, you define what the tasks are, what the documents or document sections to be worked on are, and provide a set of tools.  Once you specify these things, CELI works to automatically complete these tasks.

### The Wikipedia example use case

We have put in an example use case for celi-framework.  In this use case, we perform one-shot document generation.  We use a single wikipedia page as an example.  We then select a second wikipedia page from a different topic in the same category (bands, drugs, coutnries, etc), to use as the target.  We take only the references, not the content, from the target page and use that along with our example page to generate a new version of the target page.  This use case allows for a natural evaluation as we have the actual version of the target page to compare against for evaluation.

We provide an example script with evaluation that generates several pages from each of 3 categories, and uses BertScore to compare the generated wiki page to the original to judge quality.  To run this eval, run

`python -m celi-framework.examples.wikipedia.eval.run_eval`

We will use the Wikipedia use case to describe the overall process of configuring CELI for a new use case.

### The CELI Job Description

The overall use case is defined in the CELI Job Description object.  When you run CELI, you pass general configuration parameters and a Job Description to the main CELI processor.  The `JobDescription` defines the tasks to be accomplished and the tools to be run.  See (job_description.py)[celi-framework/core/job_description.py] for full details

The job description contains several prompt strings which describe the overall job to be run at a high level along with any general guidance for the agent.  It also contains a `task_list` and a `tool_implementations_class`.

The `task_list` is a list of `Task` objects.  When completing a job, the agent will tackle each task in this list in order.  Each task has a name and a set of details.  The details is a dictionary that will be passed directly to the LLM to describing how to accomplish the task.  

The `tool_implementations_class` is a reference to a class that derives from `ToolImplementations` and contains the tools that the LLM can use to accomplish the task.  This class is described in the next section.

### CELI Tool Implementations

Each public function in the class becomes a tool that the LLM can use.  

There is one required function, `def get_schema(self) -> Dict[str, str]`.  This function returns a dictionary describing the document sections.  The processor will work through the sections, completing the defined tasks for each section.  Each dictionary can have any string values, but it is intended to be a section number followed by a section name.

In addition to the `get_schema` function, the ToolImplementations class can have whatever other functions it needs to enable celi-framework.  Each function should be documented with type hints and a doc string.  The top section of the docstring will be included as the description of the overall function.  If the function takes arguments, there should be a section called "Args:" that contains a list of the arguments to the function and descriptions of each.  An example docstring is given below:

        """
        Extracts text from specified sections of documents.
        It handles different document types and logs any errors or warnings encountered.
        Returns concatenated text from the specified sections of the documents.
        If there is no content for the section, <empty section> will be returned.

        If the response contains "Error:", then there was a problem with the function call.

        Args:
            sections_dict_str (str): A JSON string mapping document names to their respective section numbers.  The json string will have the documents and sections in a dictionary.  The sections values should correspond to an entry in the table of contents for the specified document.
        """


## Running CELI

CELI can be run from the command line, with configuration arguments, or directly from code.

### Running from the command line

When running CELI from the command line, all arguments can be passed on the command line, provided in environment variables, or provided in a .env file in the current directory, which will get read in as environment variables.  The precedence is that command line arguments override environment variables, which override valies provided in a .env file.

When running from the command line, you need to include your JobDescription and ToolImplementations classes in the python path.  Two configuration variables control how the job is specified.
   * JOB_DESCRIPTION - This is the name of the class that contains the JobDescription.  This class must have a no-arg constructor.  For the example use case, we use "celi-framework.examples.wikipedia.job_description.job_description"
   * TOOL_CONFIG_JSON - This is the path to a JSON file.  This JSON file will be used to construct the `ToolImplementations` class.  The JSON file will be read in and converted to a dictionary.  This dictionary will then be passed as keyword arguments to the `ToolImplementations` class.

For the example use case, the `WikipediaToolImplementations` is a dataclass that takes 3 arguments (2 are required):

    @dataclass
    class WikipediaToolImplementations(ToolImplementations):
        example_url: str
        target_url: str
        ignore_updates: bool = False

The example JSON config file we use is:
    {
        "example_url": "https://en.wikipedia.org/wiki/Led_Zeppelin",
        "target_url": "https://en.wikipedia.org/wiki/Jonas_Brothers",
        "ignore_updates": true
    }

When CELI is started from the command line, to reads the JSON config file and calls `WikipediaToolImplmentations` with the 3 arguments.

### Running from code

CELI can also be run from code in addition to the command-line.  Any example of running from code can be seen in the celi-framework/examples/wikipedia/eval/run_eval.py script.  This script iterates through several test sets containing source and target wikipedia URLs.  For each, it runs CELI to generate a document, and then uses [BertScore](https://arxiv.org/abs/1904.09675) to compare the generated document to the actual target wikipedia page.  It prints out a matrix of overall results when it completes.

To run from code, you call `run_celi` passing in `CELIConfig` object.
    from celi-framework.core.runner import CELIConfig, run_celi
    run_celi(CELIConfig(...))

The `CELIConfig` object contains the instance of `JobDescripion` and `ToolImplementations` needed to run CELI as well as some other configuration parameters required.

## Running CELI from Source

If you are interested in modifying or contributiling to CELI, you can install and run it from source.  CELI uses [Poetry](https://python-poetry.org/) to manage dependencies and publishing.

1. If you don't have poetry installed already, install it using the [official installer](https://python-poetry.org/docs/#installing-with-the-official-installer).
2. Clone this repo.
3. Go the the root of the project and run `poetry install`.  This will create a virtual environment and set up all the dependencies for you.
4. From there you can use `poetry shell` to get a command line, or use a poetry plugin for your IDE to pick up dependencies.

## Contributing

We would like folks to create their own projects with the framework to address their own use cases. Please feel free to do so! Ask for help, we're here!

## License

CELI is licensed under the MIT License. Feel free to use, modify, and distribute the framework as per the license terms.

