{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonSeqCNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = torch.relu(self.conv1(x))\n",
    "        out2 = torch.relu(self.conv2(out1))\n",
    "        out3 = torch.relu(self.conv3(out2))\n",
    "        out4 = torch.relu(self.conv4(out3))\n",
    "        # Apply a 1x1 convolution to match dimensions for the skip connection\n",
    "        out2_skip = torch.relu(nn.Conv2d(64, 128, kernel_size=1)(out2))\n",
    "        # Introduce skip connection by adding outputs of conv2 and conv3\n",
    "        out4_skip = out4 + out2_skip\n",
    "        out5 = torch.relu(self.conv5(out4_skip))\n",
    "        return out5\n",
    "\n",
    "model = NonSeqCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willian/.local/lib/python3.11/site-packages/torch/jit/_trace.py:1102: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%tensor.3 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.1, %173, %174, %175) # /home/willian/.local/lib/python3.11/site-packages/torch/nn/init.py:459:0\n",
      "\t%bias.9 : Float(128, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor, %202, %203, %204) # /home/willian/.local/lib/python3.11/site-packages/torch/nn/init.py:15:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "/home/willian/.local/lib/python3.11/site-packages/torch/jit/_trace.py:1102: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 87964 / 131072 (67.1%)\n",
      "Greatest absolute difference: 0.22646202147006989 at index (0, 69, 20, 16) (up to 1e-05 allowed)\n",
      "Greatest relative difference: inf at index (0, 1, 0, 1) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    }
   ],
   "source": [
    "trace = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_output = trace(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  conv5 = self.conv5\n",
      "  conv4 = self.conv4\n",
      "  conv3 = self.conv3\n",
      "  conv2 = self.conv2\n",
      "  conv1 = self.conv1\n",
      "  input = torch.relu((conv1).forward(x, ))\n",
      "  input0 = torch.relu((conv2).forward(input, ))\n",
      "  input1 = torch.relu((conv3).forward(input0, ))\n",
      "  out4 = torch.relu((conv4).forward(input1, ))\n",
      "  data = torch.empty([128, 64, 1, 1], dtype=None, layout=None, device=torch.device(\"cpu\"), pin_memory=False)\n",
      "  tensor = torch.detach(data)\n",
      "  data0 = torch.empty([128], dtype=None, layout=None, device=torch.device(\"cpu\"), pin_memory=False)\n",
      "  tensor0 = torch.detach(data0)\n",
      "  tensor1 = torch.uniform_(tensor, -0.12499999999999999, 0.12499999999999999)\n",
      "  bias = torch.uniform_(tensor0, -0.125, 0.125)\n",
      "  _0 = torch._convolution(input0, tensor1, bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1, False, False, True, True)\n",
      "  out2_skip = torch.relu(_0)\n",
      "  input2 = torch.add(out4, out2_skip)\n",
      "  return torch.relu((conv5).forward(input2, ))\n",
      " <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(trace.code, type(trace.code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speck-rescnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
